{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95417562",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "_Words which appear frequently in similar contexts have similar meaning._\n",
    "\n",
    "(Harris 1954, Firth 1957)\n",
    "\n",
    "# Word2Vec\n",
    "\n",
    "\n",
    "__Основная идея__: поместить информацию о контекстах в вектора слов\n",
    "\n",
    "__Каким образом__: учить вектора, предсказывая по ним контексты"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c89e929",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Выученные параметры такой модели и есть наши итоговые вектора\n",
    "\n",
    "Каждый вектор (слово) должно знать о своих контекстах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0385fe6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Взять большой корпус\n",
    "* Пройтись по тексту скользящим окном, сдвигаясь по одному слову\n",
    "* По центральному слову расчитать вероятности контекстных слов\n",
    "* Сдвинуть вектора, чтобы увеличить эти вероятности\n",
    "\n",
    "![](https://i.ibb.co/fqZTRyZ/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a943d9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.ibb.co/2kZs1Mz/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95380965",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Мы хотим, чтобы наша модель думала, что тренировочные данные имеют высокую вероятность\n",
    "\n",
    "$$Likelihood = L(\\theta) = \\prod^{T}_{t=1}\\prod_{-m\\leq{j}\\leq{m},j\\neq0}P(w_{t+j}|w_{t}, \\theta)$$\n",
    "\n",
    "\n",
    "Чтобы это сделать мы используем negative log-likelihood as its loss function\n",
    "\n",
    "\n",
    "$$Loss = J(\\theta) = -\\frac{1}{T}\\sum^{T}_{t=1}\\sum_{-m\\leq{j}\\leq{m},j\\neq0}logP(w_{t+j}|w_{t}, \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0d0a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Как расчитать $P(w_{t+j}|w_{t}, \\theta)$?\n",
    "\n",
    "Для каждого слова w у нас есть два вектора:\n",
    "\n",
    "* $v_{w}$ когда оно центральное\n",
    "* $u_{w}$ когда оно контекстное\n",
    "\n",
    "![](https://i.ibb.co/0Yq6tn7/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32367101",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Как расчитать $P(w_{t+j}|w_{t}, \\theta)$?\n",
    "\n",
    "Для центрального слова $c$ и контекстного слова $o$ (o - outside):\n",
    "\n",
    "\n",
    "$$P(o|c) = \\frac {\\exp(u^{T}_{o}v_{c})} {\\sum_{w\\in V_{c}}\\exp(u^{T}_{w}v_{c})}$$\n",
    "\n",
    "\n",
    "___\n",
    "\n",
    "$$softmax(x)_{i} = \\frac {\\exp(x_{i})} {\\sum^{n}_{j=1}\\exp(x_{j})}$$\n",
    "\n",
    "Софтмакс - маппинг из случайных значений $x_{i}$ в распределение вероятнорстей $p_{i}$\n",
    "\n",
    "\"max\" - потому что увеличивает вероятность максимального $x_{i}$\n",
    "\n",
    "\"soft\" - потому что выдает некоторую вероятность меньшим $x_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4decc7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.ibb.co/6BG3b20/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81031b25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.ibb.co/NWgMwN8/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfca0cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.ibb.co/PNSGyTR/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f383f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Как обучать вектора\n",
    "\n",
    "Смотрим на лосс:\n",
    "\n",
    "$$ - logP(cute|cat) = - log \\frac{\\exp(u^{T}_{cute}v_{cat})} {\\sum_{w\\in V}\\exp(u^{T}_{w}v_{cat})} $$\n",
    "\n",
    "![](https://i.ibb.co/1TGgrxg/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2c22c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://i.ibb.co/hB490fs/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be7dbf1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$$J_{t,j}(\\theta) = -u^{T}_{cute}v_{cat} + log \\sum_{w\\in v}\\exp(u^{T}_{w}v_{cat}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa825f2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ - logP(cute|cat) = - log \\frac{\\exp(u^{T}_{cute}v_{cat})} {\\sum_{w\\in V}\\exp(u^{T}_{w}v_{cat})} $$\n",
    "\n",
    "\n",
    "![](https://i.ibb.co/dkhyD2k/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bd07c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Negative sampling\n",
    "\n",
    "![](https://i.ibb.co/pjdFGbB/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e4578",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "$$J_{t, j}(\\theta) = - log \\sigma(u^{T}_{cute}v_{cat}) - \\sum_{w\\in (w_{i1, .., w_{iK}})} \\sigma(-u^{T}_{w}v_{cat})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b1ced",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://i.ibb.co/5kXZXw9/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb35113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
