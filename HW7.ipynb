{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "from sklearn.datasets import make_blobs, make_moons\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom scipy.spatial.distance import cdist",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X, _ = make_blobs(n_samples=1000,\n                  centers=2,\n                  n_features=2,\n                  random_state=42)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(9,6))\nscatter = plt.scatter(X[:,0], X[:,1])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import pairwise_distances_argmin\n\nclass KMeans:\n    \n    def __init__(self, k, centroids=None):\n        self.k = k\n        self.centroids = centroids or None\n    \n    def fit(self, x):\n        # randomly initialize centroids in shape (k, n_features)\n        n_features = x.shape[1]\n\n        self.centroids =  np.random.rand(self.k, n_features)\n\n        done = False\n        prev_centroids = None\n\n        while not done:\n            labels = self.predict(x)\n            prev_centroids = self.centroids\n\n            self.centroids = np.array([X[labels == i].mean(0)\n                                    for i in range(self.k)])\n            # if prev centroids are same as new centroids: done = True\n            if np.allclose(self.centroids, prev_centroids):\n                done=True\ndef predict(self, x):\n        assert len(x.shape) == 2 # it's a batch, not a vector\n        y = pairwise_distances_argmin(x, self.centroids)\n        return y\nmodel = KMeans(k=2)\nmodel.fit(X)\n\ny = model.predict(X)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(9,6))\nscatter = plt.scatter(X[:,0], X[:,1], c=y)\nplt.scatter(model.centroids[:,0], model.centroids[:,1], c='red', label='centroids')\nplt.legend();\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(42)\nX, _ = make_blobs(n_samples=1000,\n                  centers=10,\n                  n_features=2,\n                  cluster_std=np.random.uniform(low=0.5, high=2, size=(10)),\n                  random_state=42)\nplt.figure(figsize=(9,6))\nscatter = plt.scatter(X[:,0], X[:,1])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=7, random_state=0).fit(X)\n# Здесь визуализируются ваши кластеры, если всё корректно получилось\n\nplt.figure(figsize=(9,6))\nscatter = plt.scatter(X[:,0], X[:,1], c=y)\nplt.scatter(model.cent[:,0], model.centroids[:,1], c='red', label='centroids')\nplt.legend();",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import sklearn\nfrom sklearn.cluster import KMeans\nhypo_clusters = range(2, 20)\nclusters_scores = {}\nfor n_clusters in hypo_clusters:\n    clust = KMeans(n_clusters=n_clusters, random_state=10)\n    labels = clust.fit_predict(X)\n\n    silhouette_sc = sklearn.metrics.silhouette_score(X, labels, metric='euclidean')\n    clusters_scores[n_clusters]=silhouette_sc\nprint(clusters_scores)\nbest_k_num = max(clusters_scores, key=clusters_scores.get)\nscore_for_best_k_num = max(clusters_scores.values())\nprint(f'Best number of clusters is {best_k_num}, score:{score_for_best_k_num}')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.cluster import KMeans\nfrom yellowbrick.cluster import SilhouetteVisualizer\nfrom yellowbrick.datasets import load_nfl\n\nmodel = KMeans(best_k_num, random_state=42)\nvisualizer = SilhouetteVisualizer(model, colors='yellowbrick')\n\nvisualizer.fit(X)        \nvisualizer.show()  ",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.cluster import DBSCAN\nfrom sklearn.datasets import make_blobs, make_moons\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nX, _ = make_moons(n_samples=100)\nplt.figure(figsize=(9,6))\nscatter = plt.scatter(X[:,0], X[:,1])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "db = DBSCAN(eps=0.1, min_samples=2).fit(X)\ncore_samples_mask = np.zeros_like(db.labels_, dtype=bool)\ncore_samples_mask[db.core_sample_indices_] = True\nlabels = db.labels_\n\nn_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n\nunique_labels = set(labels)\ncolors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\nfor k, col in zip(unique_labels, colors):\n    if k == -1:\n    \n        col = [0, 1]\n\n    class_member_mask = labels == k\n\n    xy = X[class_member_mask & core_samples_mask]\n    plt.plot(\n        xy[:, 0],\n        xy[:, 1],\n        \"o\",\n        markerfacecolor=tuple(col),\n        markeredgecolor=\"k\",\n        markersize=6,\n    )\n    xy = X[class_member_mask & ~core_samples_mask]\n    plt.plot(\n        xy[:, 0],\n        xy[:, 1],\n        \"o\",\n        markerfacecolor=tuple(col),\n        markeredgecolor=\"k\",\n        markersize=1,\n    )\n\nplt.title(f'number of clusters: {n_clusters_}')\nplt.show()\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "np.random.seed(42)\nX, _ = make_blobs(n_samples=1000,\n                  centers=15,\n                  n_features=2,\n                  cluster_std=np.random.uniform(low=0.5, high=1.2, size=(15)),\n                  random_state=42)\nplt.figure(figsize=(9,6))\nscatter = plt.scatter(X[:,0], X[:,1])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\ndf=pd.DataFrame(X,_)\nnn = NearestNeighbors(n_neighbors=11)\nneighbors = nn.fit(df)\n\ndist, ind = neighbors.kneighbors(df)\ndist = np.sort(dist[:,10], axis=0)\nfrom sklearn.neighbors import NearestNeighbors\nfrom kneed import KneeLocator\n\ni = np.arange(len(distances))\nknee = KneeLocator(i, dist, S=1, curve='convex', direction='increasing', interp_method='polynomial')\nfig = plt.figure(figsize=(5, 5))\nknee.plot_knee()\nplt.xlabel(\"Points\")\nplt.ylabel(\"Distance\")\n\nprint(f'Optimal eps value is {dist[knee.knee]}')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "dbscan_cluster = DBSCAN(eps=dist[knee.knee], min_samples=8)\ndbscan_cluster.fit(X)\n\n\nplt.scatter(X[:, 0], \nX[:, 1], \nc=dbscan_cluster.labels_, \nlabel=_)\n\n\nlabels=dbscan_cluster.labels_\nn_clus=len(set(labels))-(1 if -1 in labels else 0)\nprint(f'Num of clusters: {n_clus}')\n\n\nn_noise = list(dbscan_cluster.labels_).count(-1)\nprint(f'Noise points: {n_noise}')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}